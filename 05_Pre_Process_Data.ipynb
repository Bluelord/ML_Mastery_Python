{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_Pre-Process Data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOein4+5rYMnvWbD5kelIMr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bluelord/ML_Mastery_Python/blob/main/05_Pre_Process_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bd3E97kARE85"
      },
      "source": [
        "# Prepare Your Data\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwOashKoy3vj",
        "outputId": "1ac961b4-d72b-44cd-a3fd-001cf30c9768"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWN3XiP3ROXs"
      },
      "source": [
        "This step the is most important step before preparing the ML model, in this 4 different pre-processing techniques is show (Rescale, Standerdize, Normalize and Binarize the data). Each processing steps follows loading of data, spliting (input and output), transformation then sammarizing the changes.\n",
        "\n",
        "scikit-learn provide two ways for transforming data, they are used depanding upon the cercumstances.\n",
        "*   **Fit & Multiple Transformation** is most prefered, in this **fit()** function gives us the parameters onces for our dataset then the **transform()** is used for modeling on test or on the validating dataset.\n",
        "*   **Combined Fit-&-Transform** is used when we are interesed in ploting & summarizing the transformation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3zw2728iUgI"
      },
      "source": [
        "## Rescalr Data\n",
        "\n",
        "When data has varities of scales, ofthen used in algorithms like gradient desent or in weight inputs like regression models, neural networks or in the algorithum uses distance measures like KNN. **MinMaxScaler()** function is used for this.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFuZST9PQ-67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e5b19a7-a4b2-4243-d68d-8d80120d9676"
      },
      "source": [
        "# Rescale Data (Between 0 & 1)\n",
        "from pandas import read_csv\n",
        "from numpy import set_printoptions\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "filename = \"/content/drive/MyDrive/Colab Notebooks/ML Mastery python/Dataset/pima-indians-diabetes.csv\"\n",
        "names = ['preg', 'plas','pres','skin','test','mass','pedi','age','class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "# separate array into input & output \n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "##########################################\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "rescaledX = scaler.fit_transform(X)\n",
        "###########################################\n",
        "#Summarize transformation \n",
        "set_printoptions(precision=3)\n",
        "print(rescaledX[:,:])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.353 0.744 0.59  ... 0.501 0.234 0.483]\n",
            " [0.059 0.427 0.541 ... 0.396 0.117 0.167]\n",
            " [0.471 0.92  0.525 ... 0.347 0.254 0.183]\n",
            " ...\n",
            " [0.294 0.608 0.59  ... 0.39  0.071 0.15 ]\n",
            " [0.059 0.633 0.492 ... 0.449 0.116 0.433]\n",
            " [0.059 0.467 0.574 ... 0.453 0.101 0.033]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIEDNgf1jRVR"
      },
      "source": [
        "## Standardize Data\n",
        "\n",
        "Standardization is a useful technique to transform attributes with a Gaussian distribution and differing means and standard deviations to a standard Gaussian distribution with a mean of 0 and a standard deviation of 1. It is most suitable for techniques that assume a Gaussian distribution in the input variables and work better with rescaled data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j98t0-HjRyY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78f9f37c-2fc2-4e56-c669-7e35119e50ec"
      },
      "source": [
        "# Standardize data (0 mean, 1 std )\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler().fit(X)\n",
        "rescaledX = scaler.transform(X)\n",
        "set_printoptions(precision=3)\n",
        "print(rescaledX[:,:])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.64   0.848  0.15  ...  0.204  0.468  1.426]\n",
            " [-0.845 -1.123 -0.161 ... -0.684 -0.365 -0.191]\n",
            " [ 1.234  1.944 -0.264 ... -1.103  0.604 -0.106]\n",
            " ...\n",
            " [ 0.343  0.003  0.15  ... -0.735 -0.685 -0.276]\n",
            " [-0.845  0.16  -0.471 ... -0.24  -0.371  1.171]\n",
            " [-0.845 -0.873  0.046 ... -0.202 -0.474 -0.871]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPX_K5F6h-QK"
      },
      "source": [
        "## Normalization\n",
        "\n",
        "This Method can be usfull for the dataset which have too much of zeros in its features. This method is usfull for algorithm which used weight input values or for the distance measuring models.  Normalizer() is used for tranforming the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fHhlfrMg5_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c92dfc7-9a9e-451c-f5b7-8013f280a1a6"
      },
      "source": [
        "# Normalize data (length 1)\n",
        "from sklearn.preprocessing import Normalizer\n",
        "scaler = Normalizer().fit(X)\n",
        "NormalizedX = scaler.transform(X)\n",
        "set_printoptions(precision=3)\n",
        "print(NormalizedX[:,:])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.034 0.828 0.403 ... 0.188 0.004 0.28 ]\n",
            " [0.008 0.716 0.556 ... 0.224 0.003 0.261]\n",
            " [0.04  0.924 0.323 ... 0.118 0.003 0.162]\n",
            " ...\n",
            " [0.027 0.651 0.388 ... 0.141 0.001 0.161]\n",
            " [0.007 0.838 0.399 ... 0.2   0.002 0.313]\n",
            " [0.008 0.736 0.554 ... 0.241 0.002 0.182]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rrh-UKJvJqM"
      },
      "source": [
        "## Binarize the Data\n",
        "\n",
        "In this method the dataset is divided into two values with the help of binary threshold, in which the data above the threshold is marked as 1 & below data as 0. \n",
        "It is useful when we want to make crip values or for adding new meaning feature in our dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sVpMYxbh2Ps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11cde21b-5571-44f1-f767-5827f8cee7a3"
      },
      "source": [
        "# Binarization\n",
        "from sklearn.preprocessing import Binarizer\n",
        "binarize = Binarizer(threshold=0).fit(X)\n",
        "binaryX = binarize.transform(X)\n",
        "set_printoptions(precision=1)\n",
        "print(rescaledX[0:5,:])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.6  0.8  0.1  0.9 -0.7  0.2  0.5  1.4]\n",
            " [-0.8 -1.1 -0.2  0.5 -0.7 -0.7 -0.4 -0.2]\n",
            " [ 1.2  1.9 -0.3 -1.3 -0.7 -1.1  0.6 -0.1]\n",
            " [-0.8 -1.  -0.2  0.2  0.1 -0.5 -0.9 -1. ]\n",
            " [-1.1  0.5 -1.5  0.9  0.8  1.4  5.5 -0. ]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}