{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_Resampling Method.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMqJS4LVYSR9ffX8dEO7x83",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bluelord/ML_Mastery_Python/blob/main/07_Resampling_Method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndEQwIe9i8cX"
      },
      "source": [
        "# Evaluating the Performance of ML algorithms with Resampling**\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPXf7UtO2QTS",
        "outputId": "820e6fa8-1262-4035-9366-5569ec376ca0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzCaPUHfjhgg"
      },
      "source": [
        "Resampling method for evaluating the performance of an algorithm allows us to estimate the accuracy for our new data. If we use the same dataset which we have used for training our model for the evaluation it will result in overfitting (High Varience). After evaluating the performance, we can then re-train the final algorithm on the entire training dataset & get it ready for operational use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0vlKyd6pOXJ"
      },
      "source": [
        "## Split into Train and Test Set \n",
        "\n",
        "This is the simplest meathod for evaluating the performance of ML to use different training & testing datasets. Train the algorithm on first part, make prediction on second, evaluate the predictions against the expected results. \n",
        "The downside of this method is that it has a high variance- differance in traing and test set may result in meainingful difference in the estimate of accuracy.By specifying the random seed we ensure that we get the same random number each time we run the code & in turn the same split of data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zgi0wMJMikqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cb49fbe-a945-4b48-b678-0745182ecfad"
      },
      "source": [
        "# Evaluation using a train and a test set\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# Load Data\n",
        "filename = \"/content/drive/MyDrive/Colab Notebooks/ML Mastery python/Dataset/pima-indians-diabetes.csv\"\n",
        "names = ['preg', 'plas','pres','skin','test','mass','pedi','age','class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "# separate array into input & output \n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "#####################################\n",
        "test_size = 0.33 \n",
        "seed = 7\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=test_size, random_state=seed)\n",
        "model = LogisticRegression(solver= 'liblinear')\n",
        "model.fit(X_train, Y_train)\n",
        "result = model.score(X_test, Y_test)\n",
        "#####################################\n",
        "print(\"Accuracy: % .3f%%\" % (result*100.0))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  75.591%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY7miobPt4Jg"
      },
      "source": [
        "## K-fold Cross-Validation\n",
        "\n",
        "This method evaluate the performance of ML model with less varience than single train-test set split. Splitting the dataset into k-parts is done (k=5 | k=10), each fold is known as fold. \n",
        "\n",
        "In this k-1 folds are trained with one held baack for testing, this is repeated for each fold so that each fold of dataset is given a chance to be the held back test set. After this method we will end up with k performance score & we can summarize with mean & std of the scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG6rUDd8t4vu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feaab76c-2b52-435f-dc7b-f7c76cb8cc15"
      },
      "source": [
        "#Evaluating using Cross Validation\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "#\n",
        "#\n",
        "#####################################\n",
        "Kfold = KFold(n_splits= 10)\n",
        "model = LogisticRegression(solver= 'liblinear')\n",
        "results = cross_val_score(model,X, Y)\n",
        "#####################################\n",
        "print(\"Accuracy: % .3f%% (% .3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  76.827% ( 1.865%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djDf9akp_COd"
      },
      "source": [
        "## Leave one out Cross-Validation\n",
        "\n",
        "The size of the fold is 1 in this cross validation (k is set to the number of obsevations in the dataset). Result of this method  has large no of performance measures which gives us more resonable accuracy of our model on unseen data. The downside of this method is more expensive computation campared to the k-fold cross-validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcdatDjx_Cmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61e3018-446b-426c-9a1f-c23c7880ca99"
      },
      "source": [
        "#Evaluating using Leave one out Cross-Validation\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.model_selection import cross_val_score\n",
        "#\n",
        "#\n",
        "#####################################\n",
        "loocv = LeaveOneOut()\n",
        "model = LogisticRegression(solver= 'liblinear')\n",
        "results = cross_val_score(model,X, Y, cv=loocv)\n",
        "#####################################\n",
        "print(\"Accuracy: % .3f%% (% .3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  76.823% ( 42.196%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbHWwn83BfXM"
      },
      "source": [
        "## Repeated Random Test-Train Splits\n",
        "\n",
        "This is another type of k-fold cross-validation, in this random split of data is done, but the spiting and evaluating it multipul times. This has a speed of splittng & less variance like cross-validation. The down side of this it my produce redundancy into the evaluation due to the same data in the train & test split from run to run.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxc0n04pBfxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87863b1e-75d5-4a8a-9a9c-45598f754096"
      },
      "source": [
        "#Evaluating using Repeated Random Test-Train Splits\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import cross_val_score\n",
        "#\n",
        "#\n",
        "#####################################\n",
        "n_splits = 10\n",
        "test_size = 0.33\n",
        "seed = 7\n",
        "Kfold = ShuffleSplit(n_splits= n_splits, test_size=test_size, random_state=seed)\n",
        "model = LogisticRegression(solver= 'liblinear')\n",
        "results = cross_val_score(model,X, Y, cv=Kfold)\n",
        "#####################################\n",
        "print(\"Accuracy: % .3f%% (% .3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  76.496% ( 1.698%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbSl7WpzO0Rk"
      },
      "source": [
        "### **NOTE**\n",
        "\n",
        "> *   Generally **k-fold cross-validation** is the *godel standard* (k set to 3, 5, or 10).\n",
        "*   Using **train/test split** is good for slow algorithms & gives low bias when using large dataset.\n",
        "*  **LeaveOneOut Cross-Validation** & **Repeated Random Test-Train Splits** can be useful when trying to balance variance in  estimating performance, model training speed & dataset size.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}