{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_Spot-Check Regression Algorithms.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNQWHRq19Psttx8iWsPd+En",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bluelord/ML_Mastery_Python/blob/main/10_Spot_Check_Regression_Algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL--P5QJtveN"
      },
      "source": [
        "# Spot-Check Regression Algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHyVoIvz3Cjm",
        "outputId": "2caba91b-1c0e-4eca-da22-f5d5313923b3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJdTKto8f23L"
      },
      "source": [
        "## Linear ML Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWPL2c_if-0b"
      },
      "source": [
        "### Linear Regression\n",
        "\n",
        "This regression model assumes that the variable have Gaussian distribution and it is also assumes that the variable has relevant to the output variable &  it is not highly correlated to it , this problem is called colinearity. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jza3P0QSs65F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a1e3c0c-77d5-42c3-9a5a-a3288d64c999"
      },
      "source": [
        "# Linear Regression \n",
        "from pandas import read_csv\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        " \n",
        "# Load Data\n",
        "filename = \"/content/drive/MyDrive/Colab Notebooks/ML Mastery python/Dataset/Boston-housing.csv\"\n",
        "#names = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','MEDV']\n",
        "dataframe = read_csv(filename)\n",
        "array = dataframe.values\n",
        "X = array[:,0:13]\n",
        "Y = array[:,13]\n",
        "kfold = KFold(n_splits=10)\n",
        "model = LinearRegression()\n",
        "scoring = 'neg_mean_absolute_error'\n",
        "result = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(result.mean())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-3.583077166268338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlrEw9d2gEiL"
      },
      "source": [
        "### Ridege Regression\n",
        "\n",
        "This model is the extention of linear regression with modified loss function to minimize the the complexitas it uses the L2 Norm (Measured the sum sqared value of the coefficient).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QFI8fNMs7ON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e81d3db-8797-4409-df11-794b06951100"
      },
      "source": [
        "# Rigdge Regression\n",
        "from sklearn.linear_model import Ridge\n",
        "#\n",
        "#\n",
        "model = Ridge()\n",
        "scoring = 'neg_mean_absolute_error'\n",
        "result = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(result.mean())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-3.5498467737102906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRCtPxLygFUr"
      },
      "source": [
        "### LASSO Regression\n",
        "\n",
        "Least Absolute Shrinkage & Selection Operator (LASSO) is also a modification of linear Regression to minimize the complexity with the help of L1 Norm (Measured as the sum absolute value of the Cofficient values) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtwtI85us73e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1348aecb-3f03-4b0b-a6a7-4b06c455881b"
      },
      "source": [
        "# LASSO Regression\n",
        "from sklearn.linear_model import Lasso\n",
        "#\n",
        "#\n",
        "model = Lasso()\n",
        "scoring = 'neg_mean_absolute_error'\n",
        "result = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(result.mean())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-3.447819986449082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjm7j5rcgGea"
      },
      "source": [
        "### ElasticNet Regression\n",
        "\n",
        "This is the form of regularation regreeesion that combinesboth the Ridge & LASSO, It minimizes the complexity by penalizing the model using both L2 norm & N1 Norm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX32xsOEgHBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42d19b52-def8-43e2-c533-ec0f8f87fcac"
      },
      "source": [
        "# ElasticNet Regression\n",
        "from sklearn.linear_model import ElasticNet\n",
        "#\n",
        "#\n",
        "model = ElasticNet()\n",
        "scoring = 'neg_mean_absolute_error'\n",
        "result = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(result.mean())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-3.5488492071202726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3oMDnf8gHg6"
      },
      "source": [
        "## Nonlinear ML Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AF3N9CWR8d1"
      },
      "source": [
        "### K-Nearest Nebighors\n",
        "\n",
        "KNN locates the k most similar instances in the training dataset for the new one. In this model k neighbours, the mean & the median output variable is taken for the prediction. The distance metric is used, **Minkowski distance** is by default (Generalization of both Euclidean distance & Manhattan distance).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSFqRagygH67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a3368c3-7f53-4f94-cd6e-3c97815ef9bb"
      },
      "source": [
        "# KNN Regression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "#\n",
        "#\n",
        "model = KNeighborsRegressor()\n",
        "scoring = 'neg_mean_absolute_error'\n",
        "result = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(result.mean())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-5.42324894117647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-pbECsMTeSV"
      },
      "source": [
        "### Decision Trees\n",
        "\n",
        "Decision tree uses the training data to select the best point to split the data inorder to minimize the cost matric (Default cost function for decision tree is mean quare error) or we can specify other cost function in criterion section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6JTWi3-Te8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10e6db39-2ba9-42c6-fb71-27a758b02010"
      },
      "source": [
        "# Decision Tree Regression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "#\n",
        "#\n",
        "model = DecisionTreeRegressor()\n",
        "scoring = 'neg_mean_absolute_error'\n",
        "result = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(result.mean())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-4.188396470588236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEazDc_dTfci"
      },
      "source": [
        "### Support Vector Maachine\n",
        "\n",
        "SVM were developed for classification, then it was modified for regression as Support Vector Regression (SVR)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDib4dT9Tfxk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78a39118-7dfc-44af-a006-2f38562ff73f"
      },
      "source": [
        "# SVM Regression\n",
        "from sklearn.svm import SVR\n",
        "#\n",
        "model = SVR(gamma='auto')\n",
        "scoring = 'neg_mean_absolute_error'\n",
        "result = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(result.mean())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-6.140158782525613\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
